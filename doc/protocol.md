# Open science and open collaboration: A scoping review

TODO: Brainstorm title ideas.

## Study information

This scoping review is being conducted within the Science Collective. The overall aim of the Science Collective is to build a technical and social environment that encourages and makes it easy for science to be done in an open, rigorous, and collaborative way. 

TODO: Define science, open, collaborative

This scoping review will focus on current practices of open collaboration and open science in relation to collaboration. Open collaborative systems were defined by Forte and Lampe (2013) as: "*an online environment that (a) supports the collective production of an artifact (b) through a technologically mediated collaboration platform (c) that presents a low  barrier  to  entry  and  exit  and  (d)  supports  the  emergence  of  persistent  but  mal-leable social structures.*"

### Research aims

The aims of this scoping review are to:

- Provide an overview of current practices of research collaboration that follow basic open principles
(e.g. transparency, accessibility)
- Summarize existing online tools and resources available to improve open collaboration in research

The overarching goal of this scoping review is to better understand how researchers currently collaborate and to make recommendations for how to bridge the gap between current practices and optimal open collaboration. 

### If helpful, please select the type of aim (non-exhaustive list):

Understanding

### Anticipated Duration

- Overall: 12/2021 - 06/2023
- Research design and data collection: 12/2021 - 06/2022
- Screening resources: 06/2022 - 09/2022
- Analyses and manuscript writing: 09/2022 - 06/2023

## Design plan

### Study design

Scoping review

The protocol for this review will be registered with the (Open Science Framework)[https://osf.io/]. 

### Sampling and case selection

First, an initial search strategy was developed in consultation with a research librarian. Data was then collected in two main ways, via systematic searches of databases and hand searches.

TODO: Decide on which databases to prioritize (as six is likely too many for a scoping review)

Systematic searches were carried out in SCOPUS, Web of Science, Science Direct, Google Scholar, MEDLINE, and EMBASE. The search terms were: (open) AND (collaborat* OR science OR research OR coproduction OR co-production OR videoconferenc* OR github OR...) AND (technology OR tools OR framework* OR guideline* OR principles OR best practices OR systems OR resources). The search was limited to data available in English. No date limiters were applied. Once relevant records have been identified, software (Connected Papers)[https://www.connectedpapers.com/] will be used to scan the citations of these records for additional relevant records.

Hand searches involved contacting known researchers in the field and asking for additional relevant records that may not have been identifeid with systematic searches, including web-based records (e.g., blogs, websites, GitHub pages, social media posts).

Microsoft Excel will be used to manage records including screening decisions.

## Data Collection

### Data source(s) and data type(s)

- Journal articles published in peer-reviewed journals
- Books
- Guidelines and handbooks
- Websites and online resources

TODO: Decide if we want to include books, and if so, how many would be considered a representative sample

### Data collection tools, instruments or plans

Inclusion criteria: 
- Any formal document with advice, guidance, tools, and/or recommendations for improving open collaboration (including documents where open collaboration practices are not the primary focus)

Exclusion criteria:
- Documents that do not report on specific open collaboration practices

### Stopping criteria

In terms of database searches, we will select the first 200 references from each database search (where the results are sorted by most relevant). Hand searching will be concluded when we reach conceptual saturation (i.e., when it is determined that we are not identifying any new concepts/resources).

## Analysis Plan

### Data analysis approach

One author will extract data using a standardized and tested template via Excel. Data regarding the data source (e.g., author, title, publciation year), open collaboration practices, and any other relevant information, will be extracted. A second author will check extracted data. 

TODO: Decide on how we will extract data
TODO: Decide on who will screen/extract data

Extracted data will be summarized with the descriptive analytical method described by Arksey and O'Malley (2005). 

### Data analysis process

Data analysis will be managed in NVivo Version 12.0. The descriptive analytical method is aimed at identifying and summarizing different open collaboration practices. 

### Credibility strategies

- Screening and data extraction to be double-coded 
- Narrative synthesis to be conducted by several co-authors
- The review will be documented in accordance with the PRISMA-ScR Guidelines 

### Please provide a short rationale for why you selected particular strategies and how they are appropriate given your study's aim(s), or specify your credibility strategies if not on the above list

## Miscellaneous

### Reflection on your positionality (optional)

*No response*


