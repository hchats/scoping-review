# Open science and open collaboration: A scoping review

TODO: Brainstorm title ideas.
IDEA 1: *Towards open collaboration in medical research: A scoping review*

## Study information

This project focus on open collaboration and is being conducted within the Science Collective. The overall aim of the Science Collective is to build a technical and social environment that encourages and makes it easy for science to be done in an open, rigorous, and collaborative way. 

TODO: Define science, open, collaborative

This scoping review will focus on current practices and best practices of open collaboration and open science in relation to collaboration. Open collaborative systems were defined by Forte and Lampe (2013) as: "*an online environment that (a) supports the collective production of an artifact (b) through a technologically mediated collaboration platform (c) that presents a low  barrier  to  entry  and  exit  and  (d)  supports  the  emergence  of  persistent  but  mal-leable social structures.*"

From our work in medical research, we have experienced many different ways of working together, but rarely in the form of open collaboration. With the growing complexity and specialication in scientific practices and mehtods together with globalisation of health and environmental issues, there is a great need for a paradigm shift in research collaboration in medical research.   

### Research aims

The aims of this scoping review are to:

- Provide an overview of current practices of research collaboration that follow basic open principles
(e.g. transparency, accessibility)
- Summarize existing online tools and resources available to improve open collaboration in research

The overarching goal of this scoping review is to better understand how researchers currently collaborate and to make recommendations for how to bridge the gap between current practices and open collaborative practices. 

### If helpful, please select the type of aim (non-exhaustive list):

Understanding

### Anticipated Duration

- Overall: 12/2021 - 12/2023
- Research design and data collection: 12/2021 - 12/2022
- Screening resources: 12/2022 - 06/2023
- Analyses and manuscript writing: 06/2023 - 12/2023

## Design plan

### Study design

Scoping review

The protocol for this review will be registered with the (Open Science Framework)[https://osf.io/]. 

### Sampling and case selection

First, an initial search strategy was developed in consultation with a research librarian. Data was then collected in two main ways, via systematic searches of databases and hand searches.

TODO: Decide on which databases to prioritize (as six is likely too many for a scoping review)
*DANIEL: Google Scholar usually gives a lot of results, so I think that should be cut out. I have never heard of Science Direct, so maybe also that one. Four databases should be more than enough.*

Systematic searches were carried out in SCOPUS, Web of Science, Science Direct, Google Scholar, MEDLINE, and EMBASE. The search terms were: (open) AND (collaborat* OR science OR research OR coproduction OR co-production OR videoconferenc* OR github OR...) AND (technology OR tools OR framework* OR guideline* OR principles OR best practices OR systems OR resources). The search was limited to data available in English. No date limiters were applied. Once relevant records have been identified, software (Connected Papers)[https://www.connectedpapers.com/] will be used to scan the citations of these records for additional relevant records.

Hand searches involved contacting known researchers in the field and asking for additional relevant records that may not have been identifeid with systematic searches, including web-based records (e.g., blogs, websites, GitHub pages, social media posts).

*DANIEL: We could also do Rayyan, which is a free program for systematic reviews. We can also use Covidence, but that requires a license. I have one, but I guess it i not as open as Rayyan.*
Microsoft Excel will be used to manage records including screening decisions.

## Data Collection

### Data source(s) and data type(s)

- Journal articles published in peer-reviewed journals
- Books
- Guidelines and handbooks
- Websites and online resources

TODO: Decide if we want to include books, and if so, how many would be considered a representative sample

### Data collection tools, instruments or plans

Inclusion criteria: 
- Any formal document with advice, guidance, tools, and/or recommendations for improving open collaboration (including documents where open collaboration practices are not the primary focus). We will use the definition of open collaboration from Forte and Lampe (2013) mentioned above.

Exclusion criteria:
- Documents that do not report on specific open collaboration practices

### Stopping criteria

DANIEL: why not search all the references? Do we want to have two people review each paper or is it okay we search a database each? For this study, I would think that it is okay not to have two reviewers, as it is not a systematic reivew. It is more important to have more databases, then double check each reference. 

In terms of database searches, we will select the first 200 references from each database search (where the results are sorted by most relevant). Hand searching will be concluded when we reach conceptual saturation (i.e., when it is determined that we are not identifying any new concepts/resources).

## Analysis Plan

### Data analysis approach

One author will extract data using a standardized and tested template via Excel. Data regarding the data source (e.g., author, title, publciation year), open collaboration practices, and any other relevant information, will be extracted. A second author will check extracted data. 

TODO: Decide on how we will extract data
Daniel: we could also use a Google sheet instead - that is easier to share. If we use covidence, we can also use the data extraction form there. 

TODO: Decide on who will screen/extract data
Daniel: I don't think we have to decide who now. Ok to write as it is.

Extracted data will be summarized with the descriptive analytical method described by Arksey and O'Malley (2005). 

### Data analysis process

Data analysis will be managed in NVivo Version 12.0. The descriptive analytical method is aimed at identifying and summarizing different open collaboration practices. 

### Credibility strategies

- Screening and data extraction to be double-coded *or double-check?*
- Narrative synthesis to be conducted by several co-authors
- The review will be documented in accordance with the PRISMA-ScR Guidelines
- Preliminary results of the scoping review will be shared with groups of medical researchers to understand their collaborative practices and discuss how current practices can be shifted towards more open collaborative practices

### Please provide a short rationale for why you selected particular strategies and how they are appropriate given your study's aim(s), or specify your credibility strategies if not on the above list

In this project we will map out current practices of open collaboration and available tools and from this, together with medical researchers, come up with a set of practices to make collaborations more open. Given this practice-oriented aim and the broad search terms, it was more important to scan several databases than double-checking abstracts in few databases. The aim was to understand and create several vignettes of possible research collaborations, both open and closed, and this we conducted a narrative synthesis from the studies. In order to provide practical advise for better open collaboration practices we also decided to conduct workshops with medical researchers.

## Miscellaneous

### Reflection on your positionality (optional)

*No response*


